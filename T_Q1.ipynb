{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with BERT\n",
    "#### Below code checks the availability of the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### This cell deal with loading of data set and taking a peek into the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "Education                    0.030622\n",
       "Mechanical Engineer          0.028680\n",
       "Electrical Engineering       0.028680\n",
       "Consultant                   0.027485\n",
       "Civil Engineer               0.027186\n",
       "Sales                        0.027186\n",
       "Management                   0.026962\n",
       "Human Resources              0.026888\n",
       "Digital Media                0.026738\n",
       "Accountant                   0.026141\n",
       "Java Developer               0.025991\n",
       "Building and Construction    0.025767\n",
       "Operations Manager           0.025767\n",
       "Architecture                 0.025693\n",
       "Testing                      0.025693\n",
       "Business Analyst             0.025394\n",
       "Aviation                     0.025394\n",
       "Finance                      0.025319\n",
       "SQL Developer                0.025245\n",
       "Public Relations             0.025170\n",
       "Health and Fitness           0.024796\n",
       "Arts                         0.024796\n",
       "Network Security Engineer    0.024647\n",
       "DotNet Developer             0.024572\n",
       "Apparel                      0.023900\n",
       "Banking                      0.023452\n",
       "Automobile                   0.023377\n",
       "Web Designing                0.023079\n",
       "SAP Developer                0.022705\n",
       "Data Science                 0.022332\n",
       "ETL Developer                0.021958\n",
       "Agriculture                  0.021884\n",
       "Advocate                     0.021734\n",
       "DevOps                       0.021585\n",
       "PMO                          0.021361\n",
       "Information Technology       0.020465\n",
       "Designing                    0.019270\n",
       "Database                     0.019195\n",
       "Python Developer             0.018523\n",
       "BPO                          0.015162\n",
       "React Developer              0.013593\n",
       "Food and Beverages           0.012099\n",
       "Blockchain                   0.003510\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "def load_data_set() : \n",
    "    return pd.read_csv(\"/Users/pmanthan/Desktop/ML Practice /train.csv\")\n",
    "    \n",
    "data_set = load_data_set()\n",
    "data_set_valuecount = data_set['Category'].value_counts()\n",
    "data_set_valuecount.head()\n",
    "\n",
    "data_set.head()\n",
    "data_set[\"Category\"].value_counts()/len(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### This snippet divides the data into training and test data based on stratifies splitting so that the composure of the original data is maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12964</th>\n",
       "      <td>SQL Developer</td>\n",
       "      <td>jessica claire 100 montgomery st 10th floor 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>Public Relations</td>\n",
       "      <td>robert smith public relations specialist perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>Architecture</td>\n",
       "      <td>jessica claire 100 montgomery st 10th floor 55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>Human Resources</td>\n",
       "      <td>jessica claire montgomery street san francisco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>Food and Beverages</td>\n",
       "      <td>director food beverage robert smith phone 123 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Category                                               Text\n",
       "12964       SQL Developer  jessica claire 100 montgomery st 10th floor 55...\n",
       "2256     Public Relations  robert smith public relations specialist perso...\n",
       "6471         Architecture  jessica claire 100 montgomery st 10th floor 55...\n",
       "10408     Human Resources  jessica claire montgomery street san francisco...\n",
       "4632   Food and Beverages  director food beverage robert smith phone 123 ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_idx,test_idx in split.split(data_set,data_set[\"Category\"]) : \n",
    "    strat_train_data = data_set.loc[train_idx]\n",
    "    strat_test_data = data_set.loc[test_idx]\n",
    "    \n",
    "strat_train_data[\"Category\"].value_counts() / len(data_set)\n",
    "strat_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separates the target variables from the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12964    jessica claire 100 montgomery st 10th floor 55...\n",
       "2256     robert smith public relations specialist perso...\n",
       "6471     jessica claire 100 montgomery st 10th floor 55...\n",
       "10408    jessica claire montgomery street san francisco...\n",
       "4632     director food beverage robert smith phone 123 ...\n",
       "                               ...                        \n",
       "12495    jessica claire resumesampleexamplecom 555 4321...\n",
       "374      alejandra arts alejandraartsgmailcom 563123456...\n",
       "3971     robert smith creative designer phone 123 456 7...\n",
       "6366     jessica claire resumesampleexamplecom 555 4321...\n",
       "11463    jessica claire montgomery street san francisco...\n",
       "Name: Text, Length: 10711, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_category = strat_train_data[\"Category\"].copy()\n",
    "strat_train_text = strat_train_data.drop([\"Category\"],axis=1)\n",
    "\n",
    "strat_train_text[\"Text\"] = strat_train_text[\"Text\"].str.lower()\n",
    "strat_train_text[\"Text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this part of code i used regex for the text cleaning and spacy for the tokenization and stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12964</th>\n",
       "      <td>jessica claire 100 montgomery st 10th floor 55...</td>\n",
       "      <td>[jessica, claire, 100, montgomery, st, 10th, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>robert smith public relations specialist perso...</td>\n",
       "      <td>[robert, smith, public, relations, specialist,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6471</th>\n",
       "      <td>jessica claire 100 montgomery st 10th floor 55...</td>\n",
       "      <td>[jessica, claire, 100, montgomery, st, 10th, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10408</th>\n",
       "      <td>jessica claire montgomery street san francisco...</td>\n",
       "      <td>[jessica, claire, montgomery, street, san, fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>director food beverage robert smith phone 123 ...</td>\n",
       "      <td>[director, food, beverage, robert, smith, phon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "12964  jessica claire 100 montgomery st 10th floor 55...   \n",
       "2256   robert smith public relations specialist perso...   \n",
       "6471   jessica claire 100 montgomery st 10th floor 55...   \n",
       "10408  jessica claire montgomery street san francisco...   \n",
       "4632   director food beverage robert smith phone 123 ...   \n",
       "\n",
       "                                                  Tokens  \n",
       "12964  [jessica, claire, 100, montgomery, st, 10th, f...  \n",
       "2256   [robert, smith, public, relations, specialist,...  \n",
       "6471   [jessica, claire, 100, montgomery, st, 10th, f...  \n",
       "10408  [jessica, claire, montgomery, street, san, fra...  \n",
       "4632   [director, food, beverage, robert, smith, phon...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "punctuation_pattern = r'[^\\w\\s$]'\n",
    "strat_train_text[\"Text\"] = strat_train_text[\"Text\"].str.replace(punctuation_pattern,'',regex=True)\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_data(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Text\"].apply(tokenize_data)\n",
    "\n",
    "strat_train_text.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatixation of data into its base form using the spacy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_data (text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc ]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Text\"].apply(lemmatize_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion of the text into word embeddings using the bert model and also splitting the data into training and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 21:36:36.064563: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-05-28 21:36:36.064676: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-05-28 21:36:36.064975: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748448396.065256 3413407 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1748448396.065922 3413407 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-05-28 21:36:36.671391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"/tmp/tfhub_cache\"\n",
    "\n",
    "bert_preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    name=\"bert_preprocessor\"\n",
    ")\n",
    "\n",
    "bert_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n",
    "    name=\"bert_encoder\"\n",
    ")\n",
    "\n",
    "def bert_vectorization_batch(texts):\n",
    "    texts_tensor = tf.convert_to_tensor(texts, dtype=tf.string)\n",
    "    preprocessed = bert_preprocessor(texts_tensor)\n",
    "    outputs = bert_model(preprocessed)\n",
    "    return outputs[\"pooled_output\"]\n",
    "\n",
    "texts = strat_train_text[\"Tokens\"].astype(str).tolist()\n",
    "batch_size = 32\n",
    "all_embeddings = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "    try:\n",
    "        batch_embeddings = bert_vectorization_batch(batch_texts)\n",
    "        all_embeddings.append(batch_embeddings.numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in batch {i}-{i+batch_size}: {e}\")\n",
    "\n",
    "all_embeddings_np = np.vstack(all_embeddings)\n",
    "strat_train_text[\"BERT_Embedding\"] = list(all_embeddings_np)\n",
    "\n",
    "strat_train_text_val = strat_train_text.iloc[10000:10712]\n",
    "strat_train_category_val = strat_train_category.iloc[10000:10712]\n",
    "strat_train_text_ = strat_train_text.iloc[:10000]\n",
    "strat_train_category_ = strat_train_category.iloc[:10000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code deals with imbalance nature of the data set i found out the class weights so that the model than give more weight for the class with less number \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: np.float64(0.8896345514950166), 1: np.float64(1.0700071925197794), 2: np.float64(1.0627033891578697), 3: np.float64(0.9730377906976744), 4: np.float64(0.905151433207139), 5: np.float64(0.9378677500700476), 6: np.float64(0.9947990192436288), 7: np.float64(0.9158002735978112), 8: np.float64(1.5338526749914079), 9: np.float64(0.9916308695008147), 10: np.float64(6.6249381494309745), 11: np.float64(0.9025278058645096), 12: np.float64(0.9158002735978112), 13: np.float64(0.8554178379759775), 14: np.float64(0.8461198179979778), 15: np.float64(1.0413782375359726), 16: np.float64(1.211564564292824), 17: np.float64(1.2068685776095187), 18: np.float64(1.0774120865856602), 19: np.float64(0.8697544497856308), 20: np.float64(0.9464197356329964), 21: np.float64(1.0590887517797818), 22: np.float64(0.7594441293250142), 23: np.float64(0.8108648255813954), 24: np.float64(0.918501749331138), 25: np.float64(1.922049956933678), 26: np.float64(0.9378677500700476), 27: np.float64(0.8649224806201551), 28: np.float64(1.1363945000848752), 29: np.float64(0.894747393744988), 30: np.float64(0.8625265734716228), 31: np.float64(0.8108648255813954), 32: np.float64(0.9435517970401691), 33: np.float64(0.9025278058645096), 34: np.float64(1.0887136119694258), 35: np.float64(0.9239527982885929), 36: np.float64(1.2555326331582897), 37: np.float64(1.710835675951955), 38: np.float64(1.024250305997552), 39: np.float64(0.9212192101279758), 40: np.float64(0.8554178379759775), 41: np.float64(0.905151433207139), 42: np.float64(1.0076766764506662)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight \n",
    "\n",
    "class_weight = compute_class_weight(class_weight='balanced',classes = np.unique(data_set[\"Category\"]),y=data_set[\"Category\"])\n",
    "class_weight_dict = dict(enumerate(class_weight))\n",
    "print(\"Class weights\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data type checking due to some dtype error showed by ig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 711 entries, 2455 to 11463\n",
      "Series name: Category\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "711 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 11.1+ KB\n"
     ]
    }
   ],
   "source": [
    "isinstance(strat_train_category_, pd.DataFrame)\n",
    "strat_train_category_.head()\n",
    "strat_train_category_val.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the labels for the training of model encoding them into vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_int = label_encoder.fit_transform(strat_train_category_)\n",
    "y_val_int = label_encoder.transform(strat_train_category_val)\n",
    "\n",
    "y_train_cat = to_categorical(y_train_int)\n",
    "y_val_cat = to_categorical(y_val_int)\n",
    "\n",
    "X_train = np.stack(strat_train_text_[\"BERT_Embedding\"].values)\n",
    "X_val = np.stack(strat_train_text_val[\"BERT_Embedding\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_text_[\"BERT_Embedding\"].apply(lambda x: np.shape(x))\n",
    "y_train_cat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building of neural network for the model and compiling it and training it with the taining data set with the respective loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "metrics = [tf.keras.metrics.Accuracy(),\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall(),\n",
    "           tf.keras.metrics.F1Score()]\n",
    "\n",
    "nn_model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=[512,]),\n",
    "                                tf.keras.layers.Dense(100,activation=\"relu\"),\n",
    "                                tf.keras.layers.Dense(100,activation=\"relu\"),\n",
    "                                tf.keras.layers.Dense(43,activation=\"softmax\")])\n",
    "\n",
    "nn_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=optimizer, metrics=metrics)\n",
    "nn_model.fit(X_train,y_train_cat,\n",
    "             epochs=30,batch_size=40,validation_data=(X_val,y_val_cat),\n",
    "             class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_category = strat_test_data[\"Category\"].copy()\n",
    "strat_test_text = strat_test_data.drop([\"Category\"],axis=1)\n",
    "\n",
    "nn_model.evaluate(strat_test_text)  \n",
    "\n",
    "nn_model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
