{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "def load_data_set() : \n",
    "    return pd.read_csv(\"train.csv\")\n",
    "    \n",
    "data_set = load_data_set()\n",
    "data_set_valuecount = data_set['Category'].value_counts()\n",
    "data_set_valuecount.head()\n",
    "\n",
    "data_set.head()\n",
    "data_set[\"Category\"].value_counts()/len(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "for train_idx,test_idx in split.split(data_set,data_set[\"Category\"]) : \n",
    "    strat_train_data = data_set.loc[train_idx]\n",
    "    strat_test_data = data_set.loc[test_idx]\n",
    "    \n",
    "strat_train_data[\"Category\"].value_counts() / len(data_set)\n",
    "strat_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_category = strat_train_data[\"Category\"].copy()\n",
    "strat_train_text = strat_train_data.drop([\"Category\"],axis=1)\n",
    "\n",
    "strat_train_text[\"Text\"] = strat_train_text[\"Text\"].str.lower()\n",
    "strat_train_text[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "punctuation_pattern = r'[^\\w\\s$]'\n",
    "strat_train_text[\"Text\"] = strat_train_text[\"Text\"].str.replace(punctuation_pattern,'',regex=True)\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_data(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Text\"].apply(tokenize_data)\n",
    "\n",
    "strat_train_text.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_data (text):\n",
    "    doc = nlp(text)\n",
    "    return [token.lemma_ for token in doc ]\n",
    "\n",
    "strat_train_text[\"Tokens\"] = strat_train_text[\"Text\"].apply(lemmatize_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text  \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "bert_preprocessor = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",\n",
    "    name=\"bert_preprocessor\")\n",
    "bert_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n",
    "    name=\"bert_encoder\"\n",
    ")\n",
    "\n",
    "def bert_vectorization_batch(texts):\n",
    "    texts_tensor = tf.convert_to_tensor(texts, dtype=tf.string)\n",
    "\n",
    "    preprocessed = bert_preprocessor(texts_tensor)\n",
    "    outputs = bert_model(preprocessed)\n",
    "\n",
    "    return outputs[\"pooled_output\"]\n",
    "\n",
    "texts = strat_train_text[\"Tokens\"].astype(str).tolist()\n",
    "\n",
    "batch_size = 32\n",
    "all_embeddings = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i + batch_size]\n",
    "\n",
    "    try:\n",
    "        batch_embeddings = bert_vectorization_batch(batch_texts)\n",
    "        all_embeddings.append(batch_embeddings.numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in batch {i}-{i+batch_size}: {e}\")\n",
    "all_embeddings_np = np.vstack(all_embeddings)\n",
    "\n",
    "strat_train_text[\"BERT_Embedding\"] = list(all_embeddings_np)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
